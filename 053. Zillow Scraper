import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.service import Service

url = 'https://www.zillow.com/homes/for_rent/1-_beds/?searchQueryState=%7B%22pagination%22%3A%7B%7D%2C' \
      '%22usersSearchTerm%22%3Anull%2C%22mapBounds%22%3A%7B%22west%22%3A-122.56276167822266%2C%22east%22%3A-122' \
      '.30389632177734%2C%22south%22%3A37.69261345230467%2C%22north%22%3A37.857877098316834%7D%2C%22isMapVisible%22' \
      '%3Atrue%2C%22filterState%22%3A%7B%22fr%22%3A%7B%22value%22%3Atrue%7D%2C%22fsba%22%3A%7B%22value%22%3Afalse%7D' \
      '%2C%22fsbo%22%3A%7B%22value%22%3Afalse%7D%2C%22nc%22%3A%7B%22value%22%3Afalse%7D%2C%22cmsn%22%3A%7B%22value%22' \
      '%3Afalse%7D%2C%22auc%22%3A%7B%22value%22%3Afalse%7D%2C%22fore%22%3A%7B%22value%22%3Afalse%7D%2C%22pmf%22%3A%7B' \
      '%22value%22%3Afalse%7D%2C%22pf%22%3A%7B%22value%22%3Afalse%7D%2C%22mp%22%3A%7B%22max%22%3A3000%7D%2C%22price' \
      '%22%3A%7B%22max%22%3A872627%7D%2C%22beds%22%3A%7B%22min%22%3A1%7D%7D%2C%22isListVisible%22%3Atrue%2C%22mapZoom' \
      '%22%3A12%7D'

form_url = 'https://docs.google.com/forms/d/e/1FAIpQLSdcSTE2oDJ1xIyWRj2Wk-CttoiUFDas9pc2UqbR_0U4LmC_JA/viewform?usp' \
           '=sf_link'

headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/112.0",
            "Accept-Language": "en-US,en;q=0.5"
        }

response = requests.get(url=url, headers=headers)
data = response.content
soup = BeautifulSoup(data, "html.parser")
# finds address tag elements in property-card-data class, this represents listing prices
address_elements = soup.select('.property-card-data address')
all_addresses = [address.get_text().split(" | ")[-1] for address in address_elements]
# finds span tag elements in property-card-data class, this represents listing prices
price_elements = soup.select('.property-card-data span')
prices = [element.getText().split('+')[0].split('/mo')[0] for element in price_elements]
# finds all elements in tag 'a' with class name property-card-link
# represents links to each property listing
property_links = []
property_elements = soup.find_all('a', {'class': 'property-card-link'})
for element in property_elements:
    href = element.get("href")
    if not href.startswith('http'):
        link = f"https://www.zillow.com/{href}"
    else:
        link = href
    if link not in property_links:
        property_links.append(link)

chrome_driver_path = "C:\Development"
ser = Service(chrome_driver_path)
driver = webdriver.Chrome(service=ser)
driver.get(form_url)

# fill out Google form with data collected from Zillow
for index in range(len(all_addresses)):
    box1 = driver.find_element(by='xpath', value='//*[@id="mG61Hd"]/div[2]/div/div[2]/div[1]/div/div/div[2]/div/div['
                                                 '1]/div/div[1]/input')
    box1.send_keys(all_addresses[index])
    box2 = driver.find_element(by='xpath', value='//*[@id="mG61Hd"]/div[2]/div/div[2]/div[2]/div/div/div[2]/div/div['
                                                 '1]/div/div[1]/input')
    box2.send_keys(prices[index])
    box3 = driver.find_element(by='xpath', value='//*[@id="mG61Hd"]/div[2]/div/div[2]/div[3]/div/div/div[2]/div/div['
                                                 '1]/div/div[1]/input')
    box3.send_keys(property_links[index])
    submit = driver.find_element(by='xpath', value='//*[@id="mG61Hd"]/div[2]/div/div[3]/div[1]/div[1]/div/span/span')
    submit.click()
    submit_again = driver.find_element(by='xpath', value='/html/body/div[1]/div[2]/div[1]/div/div[4]/a')
    submit_again.click()
